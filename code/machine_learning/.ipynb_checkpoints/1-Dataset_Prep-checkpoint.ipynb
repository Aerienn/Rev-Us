{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5093c6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: SCIKIT_LEARN_INTEL=SKLEARN\n"
     ]
    }
   ],
   "source": [
    "#Enable hardware acceleration\n",
    "%env SCIKIT_LEARN_INTEL=SKLEARN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcdb9a5",
   "metadata": {},
   "source": [
    "# Dataset Prepartion\n",
    "## Dataset Loading\n",
    "### Load the JSON files into Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b969bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Define the relative file paths\n",
    "fashion_json = os.path.join(current_dir, '../../data/raw_data/AMAZON_FASHION_5.json')\n",
    "phones_json = os.path.join(current_dir, '../../data/raw_data/Cell_Phones_and_Accessories_5.json')\n",
    "grocery_json = os.path.join(current_dir, '../../data/raw_data/Grocery_and_Gourmet_Food_5.json')\n",
    "\n",
    "# Read JSON files into DataFrames\n",
    "df_fashion = pd.read_json(fashion_json, lines=True)\n",
    "df_phones = pd.read_json(phones_json, lines=True)\n",
    "df_grocery = pd.read_json(grocery_json, lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bced53",
   "metadata": {},
   "source": [
    "### Combine the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e7db48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the datasets\n",
    "df = pd.concat([df_fashion, df_phones, df_grocery], ignore_index=True)\n",
    "print(\"\\nTotal number of reviews: \",df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512b41f7",
   "metadata": {},
   "source": [
    "## Field Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c74c6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename({\"reviewText\" : \"Reviews\"}, axis=1)\n",
    "df = df.rename({\"overall\" : \"Score\"}, axis=1)\n",
    "df = df [[\"Score\", \"Reviews\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39b5b21",
   "metadata": {},
   "source": [
    "## Missing and Duplicate Data Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c1adc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_checker(df):\n",
    "    # Get the missing reviews\n",
    "    missing_reviews = df['Reviews'].isnull()\n",
    "    \n",
    "    print(\"Missing data:\\n\", missing_reviews.sum())\n",
    "    print(df[missing_reviews])\n",
    "    \n",
    "missing_checker(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee088132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Missing Data\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Check again\n",
    "missing_checker(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6d3a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_checker(df):\n",
    "    # Get the duplicate reviews\n",
    "    duplicate_reviews = df.duplicated(subset='Reviews')\n",
    "    \n",
    "    print(\"Duplicate Reviews:\\n\", duplicate_reviews.sum())\n",
    "    print(df[duplicate_reviews])\n",
    "    \n",
    "duplicate_checker(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0783ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the duplicates but keep the first instance\n",
    "df.drop_duplicates(subset='Reviews', keep='first', inplace=True)\n",
    "duplicate_checker(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d537ca",
   "metadata": {},
   "source": [
    "## Feedback Mapping of Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c2a8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np                       # MD array and Matrices\n",
    "\n",
    "conditions = [\n",
    "    (df['Score'] >= 4),\n",
    "    (df['Score'] == 3),\n",
    "    (df['Score'] <= 2)\n",
    "    ]\n",
    "feedback_values = ['Positive',\n",
    "                   'Neutral',\n",
    "                   'Negative']\n",
    "df['Feedback'] = np.select(conditions, feedback_values)\n",
    "\n",
    "\n",
    "feedback_counts = df['Feedback'].value_counts()\n",
    "print(feedback_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9e5baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # Data Visualization\n",
    "\n",
    "df['Feedback'].value_counts().sort_index().plot.bar(color=['maroon', 'steelblue', 'limegreen'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4424e858",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Total number of reviews:\",df.shape[0])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10d2985",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c9942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from data_preprocess import text_cleaner, stop_words\n",
    "\n",
    "#Test the imported module\n",
    "text = \"Iâ€™m never gonna give you up. But I shouldn't say that I can't bear to lose you.\\n https://youtube.com <strong> Bold and brash </strong> \\n<a href='https://www.w3schools.com'>Visit W3Schools</a>\"\n",
    "cleaned_words = text_cleaner(text)\n",
    "print(cleaned_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47daeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Reviews'] = df['Reviews'].apply(text_cleaner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f0a717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing and dupe data again isn't substantial that text cleaner wiped it out.\n",
    "missing_checker(df)\n",
    "duplicate_checker(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550a0a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop\n",
    "df.dropna(inplace=True)\n",
    "missing_checker(df)\n",
    "df.drop_duplicates(subset='Reviews', keep='first', inplace=True)\n",
    "duplicate_checker(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f244c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a44da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to the new CSV file\n",
    "df.to_csv(os.path.join(current_dir, '../../data/processed_data/prep_reviews.csv'), index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdc41cc",
   "metadata": {},
   "source": [
    "# PROCEED TO MODEL TRAINING"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
